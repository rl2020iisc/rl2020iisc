<!DOCTYPE html PUBLIC "-//W3C/DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html><head>


<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title> Reinforcement Learning </title>

<link type="text/css" rel="stylesheet" href="stdcss.css">

</head><body><a name="top"></a>



<div class="header">


 <table cellpadding="7">
 <tbody><tr>

<td width="29px" bgcolor="white" align="right">
</td>
<td width="1px" bgcolor="white" align="right">
</td>


 <td>


<table><tbody><tr>


<td>


<h1> <font style="font-variant: normal;"> E1 277 (3:1) Reinforcement Learning <font size="1.5pt;" color="#660000"><span style="font-variant: normal;"></span></font></font></h1><font style="font-variant: normal;">  
</font><p><font style="font-variant: normal;"> Department of Computer Science and Automation ( <a href="http://www.csa.iisc.ac.in/"> CSA </a> )
<br> Indian Institute of Science ( <a href="http://www.iisc.ac.in/">IISc </a> ), Bangalore
</font></p>
<font style="font-variant: normal;"> 

</font><p><br>
<b> Class Timing </b> : Monday &amp; Wednesday, &nbsp; 2:00-&nbsp;3:30pm,&nbsp; January - May, 2020. <br><br> 
<b> Class Room </b> : CSA Department, Room No. 112 <br><br>
<b> Course Instructor </b> : <a href="https://www.csa.iisc.ac.in/~shalabh/"> Prof. Shalabh Bhatnagar </a> [ shalabh AT iisc.ac.in ] <br> <br>
<b> TA </b> :  <br><br>
</p>

 <dt></dt><h3> Announcements </h3>
<dd><ul>

 <dt></dt><li> ---- <b> </b> </li>
 </ul></dd>
 

<dt></dt><h3> Syllabus </h3>
<dd><ul>
 <dt></dt><li> Introduction to reinforcement learning </li>
 <dt></dt><li> Introduction to stochastic dynamic programming </li>
 <dt></dt><li> Finite and infinite horizon models </li>
 <dt></dt><li> Dynamic programming algorithm </li>
 <dt></dt><li> Infinite horizon discounted cost and average cost problems </li>
 <dt></dt><li> Numerical solution methodologies </li>
 <dt></dt><li> Full state representations </li>
 <dt></dt><li> Function approximation techniques </li>
 <dt></dt><li> Approximate dynamic programming </li>
 <dt></dt><li> Partially observable Markov decision processes </li>
 <dt></dt><li> Q-learning </li>
 <dt></dt><li> Temporal difference learning </li>
 <dt></dt><li> Actor-critic algorithms </li>


</ul></dd>
 

 </ul></dd>

    
<dt></dt><h3> Reference Books </h3>
<dd><ul>
 <dt></dt><li> Neuro-Dynamic Programming: &nbsp; <em> D.P.Bertsekas and J.N.Tsitsiklis </em> , Athena Scientific, 1996.</li>
 <dt></dt><li> Reinforcement Learning: An Introduction: &nbsp; <em> R.S.Sutton and A.G.Barto </em> , MIT Press, 1998, 2018.</li>
 <dt></dt><li> Dynamic Programming and Optimal Control, Vol.I: &nbsp; <em>D.P.Bertsekas </em> , Athena Scientific, 2005. </li><br>
</ul></dd>

  


 
<dt> </dt> <h3> Exam Dates </h3>
<dd><ul>
 <dt></dt><li> <b>1st mid-term Test:</b> TBD </li>
 <dt></dt><li> <b>2nd mid-term Test:</b> TBD </li>
  <dt></dt><li> <b>Final Exam:</b> TBD </li>


</ul></dd>
 
<dt></dt><h3> Lecture Schedule </h3>

</td>
 </tr>
</tbody></table>

</td></tr></tbody></table></div></body></html>
